data <- substr(medidas, start = local[1]+1, stop = local[1]+10) %>%
as.numeric() %>% data.frame()
colnames(data) <- "Prx"
data
}
df1_table <- create_amostras_df(medidas_1, local)
head(df1_table)
df2_table <- create_amostras_df(medidas_2, local)
head(df2_table)
hist(df1_table$Prx, probability = TRUE, breaks = 100, main = 'Estimação do Histograma df_table1')
# Apresentando duas formas de gerar o histograma.
ggplot(df2_table, aes(x = Prx)) + geom_histogram(aes(y =..density..),
bins   = 50,
colour = "black",
fill = "white")
hist(df2_table$Prx, probability = TRUE, breaks = 100, main = 'Estimação do Histograma')
get_coords <- function(data) {
gps_lat_ponto_1  = data[12,1]
# gps_lat_ponto_1
gps_long_ponto_1 = data[13,1]
# gps_long_ponto_1
# Conversão de grau, minuto fracionado
grau_lat_ponto_1        = substr(gps_lat_ponto_1, start = 17, stop = 18)
minuto_lat_ponto_1      = substr(gps_lat_ponto_1, start = 19, stop = 26)
grau_long_ponto_1       = substr(gps_long_ponto_1, start = 18, stop = 19)
minuto_long_ponto_1     = substr(gps_long_ponto_1, start = 20, stop = 27)
# Composição dos valores numéricos de latitude e longitude
data.frame(
lat = as.numeric(grau_lat_ponto_1) + as.numeric(minuto_lat_ponto_1)/60,
lng = as.numeric(grau_long_ponto_1) + as.numeric(minuto_long_ponto_1)/60
)
}
coord <- get_coords(dataset_1)
coord
leaflet() %>%
addTiles() %>%
addMarkers(lng = coord$lng, lat = coord$lat,
popup = 'ponto a',
clusterOptions = markerClusterOptions())
library(stringr)
dataset_2 <- read.delim("Datasets/dataset_2.csv",stringsAsFactors = FALSE)
dataset_1 <- read.delim("Datasets/dataset_1.csv",stringsAsFactors = FALSE)
dataset_2 <- read.delim("Datasets/dataset_2.csv",stringsAsFactors = FALSE)
dataset_1
dataset_2
dataset_1[12,1]
# A partir da observação (view) do dataset_1 e dataset_2, podemos obter
# as informações de geolocalização de cada medida
gps_lat_ponto_1  = dataset_1[12,1]
# gps_lat_ponto_1
gps_long_ponto_1 = dataset_1[13,1]
# Conversão de grau, minuto fracionado
grau_lat_ponto_1        = substr(gps_lat_ponto_1, start = 17, stop = 18)
minuto_lat_ponto_1      = substr(gps_lat_ponto_1, start = 19, stop = 26)
grau_long_ponto_1       = substr(gps_long_ponto_1, start = 18, stop = 19)
minuto_long_ponto_1     = substr(gps_long_ponto_1, start = 20, stop = 27)
# Composição dos valores numéricos de latitude e longitude
gps_lat_ponto_1_decimal  = as.numeric(grau_lat_ponto_1) + as.numeric(minuto_lat_ponto_1)/60
gps_long_ponto_1_decimal = as.numeric(grau_long_ponto_1) + as.numeric(minuto_long_ponto_1)/60
leaflet() %>%
addTiles() %>%
addMarkers(lng = gps_long_ponto_1_decimal, lat = gps_lat_ponto_1_decimal,
popup = 'ponto 21',
clusterOptions = markerClusterOptions())
get_coords <- function(data) {
gps_lat_ponto_1  = data[12,1]
# gps_lat_ponto_1
gps_long_ponto_1 = data[13,1]
# gps_long_ponto_1
# Conversão de grau, minuto fracionado
grau_lat_ponto_1        = substr(gps_lat_ponto_1, start = 17, stop = 18)
minuto_lat_ponto_1      = substr(gps_lat_ponto_1, start = 19, stop = 26)
grau_long_ponto_1       = substr(gps_long_ponto_1, start = 18, stop = 19)
minuto_long_ponto_1     = substr(gps_long_ponto_1, start = 20, stop = 27)
# Composição dos valores numéricos de latitude e longitude
data.frame(
lat = (-1)*(as.numeric(grau_lat_ponto_1) + as.numeric(minuto_lat_ponto_1)/60),
lng = (-1)*(as.numeric(grau_long_ponto_1) + as.numeric(minuto_long_ponto_1)/60)
)
}
coord <- get_coords(dataset_1)
coord
library(stringr)
dataset_1 <- read.delim("Datasets/dataset_1.csv",stringsAsFactors = FALSE)
dataset_2 <- read.delim("Datasets/dataset_2.csv",stringsAsFactors = FALSE)
dataset_1
dataset_2
obter_medidas <- function(data) {
data[21:nrow(data)-1,]
}
medidas_1 <- obter_medidas(dataset_1)
head(medidas_1)
medidas_2 <- obter_medidas(dataset_2)
head(medidas_2)
# A partir de uma amostra descobre onde se encontra a primeira ","
amostra <- medidas_1[21]
local <- str_locate(amostra,",")
create_amostras_df = function(medidas, local) {
data <- substr(medidas, start = local[1]+1, stop = local[1]+10) %>%
as.numeric() %>% data.frame()
colnames(data) <- "Prx"
data
}
df1_table <- create_amostras_df(medidas_1, local)
head(df1_table)
df2_table <- create_amostras_df(medidas_2, local)
head(df2_table)
hist(df1_table$Prx, probability = TRUE, breaks = 100, main = 'Estimação do Histograma df_table1')
# Apresentando duas formas de gerar o histograma.
ggplot(df2_table, aes(x = Prx)) + geom_histogram(aes(y =..density..),
bins   = 50,
colour = "black",
fill = "white")
hist(df2_table$Prx, probability = TRUE, breaks = 100, main = 'Estimação do Histograma')
get_coords <- function(data) {
gps_lat_ponto_1  = data[12,1]
# gps_lat_ponto_1
gps_long_ponto_1 = data[13,1]
# gps_long_ponto_1
# Conversão de grau, minuto fracionado
grau_lat_ponto_1        = substr(gps_lat_ponto_1, start = 17, stop = 18)
minuto_lat_ponto_1      = substr(gps_lat_ponto_1, start = 19, stop = 26)
grau_long_ponto_1       = substr(gps_long_ponto_1, start = 18, stop = 19)
minuto_long_ponto_1     = substr(gps_long_ponto_1, start = 20, stop = 27)
# Composição dos valores numéricos de latitude e longitude
data.frame(
lat = (-1)*(as.numeric(grau_lat_ponto_1) + as.numeric(minuto_lat_ponto_1)/60),
lng = (-1)*(as.numeric(grau_long_ponto_1) + as.numeric(minuto_long_ponto_1)/60)
)
}
coord <- get_coords(dataset_1)
coord
leaflet() %>%
addTiles() %>%
addMarkers(lng = coord$lng, lat = coord$lat,
popup = 'ponto a',
clusterOptions = markerClusterOptions())
library(ggplot2)
library(maps)
library(mapdata)
library(leaflet)
library(stringr)
library(stringr)
library(ggplot2)
library(maps)
library(mapdata)
library(leaflet)
library(stringr)
dataset_1 <- read.delim("Datasets/dataset_1.csv",stringsAsFactors = FALSE)
dataset_2 <- read.delim("Datasets/dataset_2.csv",stringsAsFactors = FALSE)
dataset_1
dataset_2
obter_medidas <- function(data) {
data[21:nrow(data)-1,]
}
medidas_1 <- obter_medidas(dataset_1)
head(medidas_1)
medidas_2 <- obter_medidas(dataset_2)
head(medidas_2)
# A partir de uma amostra descobre onde se encontra a primeira ","
amostra <- medidas_1[21]
local <- str_locate(amostra,",")
create_amostras_df = function(medidas, local) {
data <- substr(medidas, start = local[1]+1, stop = local[1]+10) %>%
as.numeric() %>% data.frame()
colnames(data) <- "Prx"
data
}
df1_table <- create_amostras_df(medidas_1, local)
head(df1_table)
df2_table <- create_amostras_df(medidas_2, local)
head(df2_table)
hist(df1_table$Prx, probability = TRUE, breaks = 100, main = 'Estimação do Histograma df_table1')
# Apresentando duas formas de gerar o histograma.
ggplot(df2_table, aes(x = Prx)) + geom_histogram(aes(y =..density..),
bins   = 50,
colour = "black",
fill = "white")
hist(df2_table$Prx, probability = TRUE, breaks = 100, main = 'Estimação do Histograma')
get_coords <- function(data) {
gps_lat_ponto_1  = data[12,1]
# gps_lat_ponto_1
gps_long_ponto_1 = data[13,1]
# gps_long_ponto_1
# Conversão de grau, minuto fracionado
grau_lat_ponto_1        = substr(gps_lat_ponto_1, start = 17, stop = 18)
minuto_lat_ponto_1      = substr(gps_lat_ponto_1, start = 19, stop = 26)
grau_long_ponto_1       = substr(gps_long_ponto_1, start = 18, stop = 19)
minuto_long_ponto_1     = substr(gps_long_ponto_1, start = 20, stop = 27)
# Composição dos valores numéricos de latitude e longitude
data.frame(
lat = (-1)*(as.numeric(grau_lat_ponto_1) + as.numeric(minuto_lat_ponto_1)/60),
lng = (-1)*(as.numeric(grau_long_ponto_1) + as.numeric(minuto_long_ponto_1)/60)
)
}
coord <- get_coords(dataset_1)
coord
leaflet() %>%
addTiles() %>%
addMarkers(lng = coord$lng, lat = coord$lat,
popup = 'ponto a',
clusterOptions = markerClusterOptions())
head(dataset_1)
head(dataset_1, 21)
head(dataset_2, 21)
library(stringr)
library(ggplot2)
library(maps)
library(mapdata)
library(leaflet)
library(stringr)
dataset_1 <- read.delim("Datasets/dataset_1.csv",stringsAsFactors = FALSE)
dataset_2 <- read.delim("Datasets/dataset_2.csv",stringsAsFactors = FALSE)
head(dataset_1, 21)
head(dataset_2, 21)
obter_medidas <- function(data) {
data[21:nrow(data)-1,]
}
medidas_1 <- obter_medidas(dataset_1)
head(medidas_1)
medidas_2 <- obter_medidas(dataset_2)
head(medidas_2)
# A partir de uma amostra descobre onde se encontra a primeira ","
amostra <- medidas_1[21]
local <- str_locate(amostra,",")
create_amostras_df = function(medidas, local) {
data <- substr(medidas, start = local[1]+1, stop = local[1]+10) %>%
as.numeric() %>% data.frame()
colnames(data) <- "Prx"
data
}
df1_table <- create_amostras_df(medidas_1, local)
head(df1_table)
df2_table <- create_amostras_df(medidas_2, local)
head(df2_table)
hist(df1_table$Prx, probability = TRUE, breaks = 100, main = 'Estimação do Histograma df_table1')
# Apresentando duas formas de gerar o histograma.
ggplot(df2_table, aes(x = Prx)) + geom_histogram(aes(y =..density..),
bins   = 50,
colour = "black",
fill = "white")
hist(df2_table$Prx, probability = TRUE, breaks = 100, main = 'Estimação do Histograma')
get_coords <- function(data) {
gps_lat_ponto_1  = data[12,1]
# gps_lat_ponto_1
gps_long_ponto_1 = data[13,1]
# gps_long_ponto_1
# Conversão de grau, minuto fracionado
grau_lat_ponto_1        = substr(gps_lat_ponto_1, start = 17, stop = 18)
minuto_lat_ponto_1      = substr(gps_lat_ponto_1, start = 19, stop = 26)
grau_long_ponto_1       = substr(gps_long_ponto_1, start = 18, stop = 19)
minuto_long_ponto_1     = substr(gps_long_ponto_1, start = 20, stop = 27)
# Composição dos valores numéricos de latitude e longitude
data.frame(
lat = (-1)*(as.numeric(grau_lat_ponto_1) + as.numeric(minuto_lat_ponto_1)/60),
lng = (-1)*(as.numeric(grau_long_ponto_1) + as.numeric(minuto_long_ponto_1)/60)
)
}
coord <- get_coords(dataset_1)
coord
leaflet() %>%
addTiles() %>%
addMarkers(lng = coord$lng, lat = coord$lat,
popup = 'ponto a',
clusterOptions = markerClusterOptions())
n <- 100
amostras <- seq(1, 100, length.out = n)
#Ruido
?rnorm
# Função hipótese verdadeira
h_x <- 3*x + 30
# Quantidade de amostras
n <- 100
#Gerando as amostras
x <- seq(1, 100, length.out = n)
# Função hipótese verdadeira
h_x <- 3*x + 30
set.seed(123)
#Ruido
?rnorm
epilson <- rnorm(n, 0, 15)
epilson
# Quantidade de amostras
n <- 100
#Gerando as amostras
x <- seq(1, 100, length.out = n)
# Função hipótese verdadeira
h_x <- 3*x + 30
set.seed(123)
#Ruido
?rnorm
epilson <- rnorm(n, 0, 15)
# Variável de saída
y <- h_x + epsilon
# Quantidade de amostras
n <- 100
#Gerando as amostras
x <- seq(1, 100, length.out = n)
# Função hipótese verdadeira
h_x <- 3*x + 30
set.seed(123)
#Ruido
?rnorm
epsilon <- rnorm(n, 0, 15)
# Variável de saída
y <- h_x + epsilon
plot(x, y, col=1, pch=1, main = 'Gráfico de Dispersão',
col.main = 'black',
xlab = 'Variável Explanatória',
ylab = 'Variável de Saída')
grid()
hist(y)
hist(y, title("Histograma da variável de saída"))
hist(y, title("Histograma da variável de saída"))
hist(y, title = "Histograma da variável de saída")
hist(y)
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 32
MSE = (1/n)*sum(((y - h_x_estimado)^2))
(1/n)*sum(((y - h_x)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 28
MSE = (1/n)*sum(((y - h_x_estimado)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 32
MSE = (1/n)*sum(((y - h_x_estimado)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 36
MSE = (1/n)*sum(((y - h_x_estimado)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 40
MSE = (1/n)*sum(((y - h_x_estimado)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 400
MSE = (1/n)*sum(((y - h_x_estimado)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 50
MSE = (1/n)*sum(((y - h_x_estimado)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 50
MSE = (1/n)*sum(((y - h_x_estimado)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 50
MSE = (1/n)*sum(((y - h_x_estimado)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 55
MSE = (1/n)*sum(((y - h_x_estimado)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 40
MSE = (1/n)*sum(((y - h_x_estimado)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 35
MSE = (1/n)*sum(((y - h_x_estimado)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 32
MSE = (1/n)*sum(((y - h_x_estimado)^2))
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 32
MSE = (1/n)*sum(((y - h_x_estimado)^2))
MSE
?rep
std_vector = seq(1, 20, length.out = 100)
std_vector = seq(1, 20, length.out = 100) %>% sort(decreasing = TRUE)
library(dplyr)
library(dplyr)
library(dplyr)
std_vector = seq(1, 20, length.out = 100) %>% sort(decreasing = TRUE)
#Construindo o vetor com os valores ordenados em ordem descrescente.
std_vector = seq(1, 20, length.out = 100) %>% sort(decreasing = TRUE)
std_vector
#Construindo o vetor com os valores ordenados em ordem descrescente.
std_vector = seq(1, 20, length.out = 100) %>% sort(decreasing = TRUE)
#Inicializando os vetores
MSE_vector = rep(0,length(std_vector))
MSE        = rep(0,num_iter)
num_iter = 1000
#Construindo o vetor com os valores ordenados em ordem descrescente.
std_vector = seq(1, 20, length.out = 100) %>% sort(decreasing = TRUE)
#Inicializando os vetores
MSE_vector = rep(0,length(std_vector))
MSE        = rep(0,num_iter)
std_vector
n = 100
num_iter = 1000
#Construindo o vetor com os valores ordenados em ordem descrescente.
std_vector = seq(1, 20, length.out = 100) %>% sort(decreasing = TRUE)
x = seq(1, 100, length.out = n)
#Inicializando os vetores
MSE_vector = rep(0,length(std_vector))
MSE        = rep(0,num_iter)
std_vector
n = 100
num_iter = 1000
#Construindo o vetor com os valores ordenados em ordem descrescente.
std_vector = seq(1, 20, length.out = 100) %>% sort(decreasing = TRUE)
x = seq(1, 100, length.out = n)
# Função hipótese verdadeira
h_x <- 3*x + 30
#Inicializando os vetores
MSE_vector = rep(0,length(std_vector))
MSE        = rep(0,num_iter)
std_vector
# Função hipótese verdadeira
h_x <- 3*x + 30
h_x
for(k in 1:length(std_vector)) {
for(i in 1:num_iter) {
# Ruído
epsilon <- rnorm(n, 0, std_vector[k])
# Variável de saída
y <- h_x + epsilon
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 32
# Erro quadrático médio para uma iteração
MSE[i] = (1/n)*sum(((y - h_x_estimado)^2))
}
# Erro quadrático médio para várias iterações
MSE_vector[k] = mean(MSE)
}
plot(std_vector,MSE_vector,col=1, pch=1, main = 'MSE - Mean Squared Error',
col.main = 'black',
xlab = 'Desvio padrão dos Erros',
ylab = 'MSE')
grid()
for(k in 1:length(std_vector)) {
for(i in 1:num_iter) {
# Ruído
epsilon <- rnorm(n, 0, std_vector[k])
epilson
# Variável de saída
y <- h_x + epsilon
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 32
# Erro quadrático médio para uma iteração
MSE[i] = (1/n)*sum(((y - h_x_estimado)^2))
}
# Erro quadrático médio para várias iterações
MSE_vector[k] = mean(MSE)
}
epilson
?rnorm()
rnorm(n, 0, std_vector[1])
rnorm(n, 0, std_vector[1])
rnorm(n, 0, std_vector[1])
std_vector[1]
rnorm(n, 0, 20)
rnorm(n, 0, 20)
library(dplyr)
n = 100
num_iter = 1000
#Construindo o vetor com os valores ordenados em ordem descrescente.
std_vector = seq(1, 20, length.out = 100) %>% sort(decreasing = TRUE)
x = seq(1, 100, length.out = n)
#Inicializando os vetores
MSE_vector = rep(0,length(std_vector))
MSE        = rep(0,num_iter)
std_vector
# Função hipótese verdadeira
h_x <- 3*x + 30
h_x
for(k in 1:length(std_vector)) {
for(i in 1:num_iter) {
# Ruído
epsilon <- rnorm(n, 0, std_vector[k])
# Variável de saída
y <- h_x + epsilon
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 32
# Erro quadrático médio para uma iteração
MSE[i] = (1/n)*sum(((y - h_x_estimado)^2))
}
# Erro quadrático médio para várias iterações
MSE_vector[k] = mean(MSE)
}
plot(std_vector,MSE_vector,col=1, pch=1, main = 'MSE - Mean Squared Error',
col.main = 'black',
xlab = 'Desvio padrão dos Erros',
ylab = 'MSE')
grid()
seq(10, 100, 5)
num_iter <- 1000
# Cria uma sequêcia de 10 a 100 de 5 em 5 (10, 15, 20 ... 100)
n_vector = seq(10, 100, 5)
# Inicialização dos vetores de MSE
MSE_vector = rep(0,length(n_vector))
MSE        = rep(0,num_iter)
n_vector
# Função hipótese verdadeira
# Função hipótese verdadeira
h_x <- 3*x + 30
h_x
for (k in 1:length(std_vector)){
# Crie um vetor de índices x variando de 0 a 100. Utilize a função seq - sequence
# x = seq(from = 0, to = 100, by = 1)
n = std_vector[k]
x = seq(1, 100, length.out = n)
# Função hipótese verdadeira
h_x <- 3*x + 30
for (i in 1:num_iter){
# Ruído
std = 0.5
epsilon <- rnorm(n, 0, std)
# Variável de saída
y <- h_x + epsilon
# Função hipótese Estimada
h_x_estimado <- 2.8*x + 32
# Erro quadrático médio para uma iteração
MSE[i] = (1/n)*sum(((y - h_x_estimado)^2))
}
# Erro quadrático médio para várias iterações
MSE_vector[k] = mean(MSE)
}
